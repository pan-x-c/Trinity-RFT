actor_rollout_ref:
  hybrid_engine: True
  model:
    external_lib: null
    override_config: { }
    enable_gradient_checkpointing: True
    use_remove_padding: True
  actor:
    strategy: fsdp
    ppo_mini_batch_size: 16
    ppo_micro_batch_size_per_gpu: 1
    use_dynamic_bsz: True
    ppo_max_token_len_per_gpu: 20000  # Adjusted for alfworld longer sequences
    grad_clip: 1.0
    clip_ratio: 0.2
    ppo_epochs: 1
    shuffle: False
    ulysses_sequence_parallel_size: 1
    optim:
      lr: 1e-6
      lr_warmup_steps_ratio: 0.
      total_training_steps: -1  # Will be overridden by program
    fsdp_config:
      wrap_policy:
        min_num_params: 0
      param_offload: False
      optimizer_offload: False
      fsdp_size: -1
  ref:
    fsdp_config:
      param_offload: False
      wrap_policy:
        min_num_params: 0
    log_prob_micro_batch_size_per_gpu: 8
    log_prob_use_dynamic_bsz: ${actor_rollout_ref.actor.use_dynamic_bsz}
    log_prob_max_token_len_per_gpu: ${actor_rollout_ref.actor.ppo_max_token_len_per_gpu}
    ulysses_sequence_parallel_size: ${actor_rollout_ref.actor.ulysses_sequence_parallel_size}

trainer:
  balance_batch: True
  resume_mode: disable
  default_hdfs_dir: null
  remove_previous_ckpt_in_save: True
  del_local_ckpt_after_load: False
  val_before_train: False
